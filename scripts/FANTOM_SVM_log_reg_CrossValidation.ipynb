{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from astropy.units import one\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, \\\n",
    "                            precision_recall_curve, average_precision_score, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "# the distribution of sequence length\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# from torch import Tensor\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import torch.nn as nn\n",
    "# import torch.utils.data as data_utils\n",
    "# import torch.optim.lr_scheduler as lr_scheduler \n",
    "# import matplotlib.pyplot as plt\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn tools for model training and assesment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score, balanced_accuracy_score, matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '../'\n",
    "\n",
    "#ds_dir = f'{project_dir}data/seq/'\n",
    "ds_dir = f'{project_dir}data/processed/'\n",
    "\n",
    "snapshot_dir = f'{project_dir}snapshots/'\n",
    "\n",
    "classes = ['lnc_e','lnc_p']\n",
    "class_suffix = '_noN'\n",
    "\n",
    "neg_filename = f'{ds_dir}train_val_test__80_20/{classes[0]}{class_suffix}_tr_val.csv'\n",
    "pos_filename = f'{ds_dir}train_val_test__80_20/{classes[1]}{class_suffix}_tr_val.csv'\n",
    "\n",
    "test_neg_filename = f'{ds_dir}train_val_test__80_20/{classes[0]}{class_suffix}_test.csv'\n",
    "test_pos_filename = f'{ds_dir}train_val_test__80_20/{classes[1]}{class_suffix}_test.csv'\n",
    "\n",
    "\n",
    "# feature_filenames_class_0 = [f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_1mer_features_tr_val.csv',\n",
    "#                              f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_2mer_features_tr_val.csv',\n",
    "#                              f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_3mer_features_tr_val.csv']\n",
    "# feature_filenames_class_1 = [f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_1mer_features_tr_val.csv',\n",
    "#                              f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_2mer_features_tr_val.csv',\n",
    "#                              f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_3mer_features_tr_val.csv']\n",
    "\n",
    "\n",
    "# test_feature_filenames_class_0 = [f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_1mer_features_test.csv',\n",
    "#                                   f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_2mer_features_test.csv',\n",
    "#                                   f'{ds_dir}train_val_test/{classes[0]}{class_suffix}_3mer_features_test.csv']\n",
    "# test_feature_filenames_class_1 = [f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_1mer_features_test.csv',\n",
    "#                                   f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_2mer_features_test.csv',\n",
    "#                                   f'{ds_dir}train_val_test/{classes[1]}{class_suffix}_3mer_features_test.csv']\n",
    "\n",
    "\n",
    "bio_feature_filenames_class_0 = [f'{ds_dir}train_val_test__80_20/{classes[0]}_nosim.fa.matrix_tr_val.csv']\n",
    "bio_feature_filenames_class_1 = [f'{ds_dir}train_val_test__80_20/{classes[1]}_nosim.fa.matrix_tr_val.csv']\n",
    "\n",
    "\n",
    "test_bio_feature_filenames_class_0 = [f'{ds_dir}train_val_test__80_20/{classes[0]}_nosim.fa.matrix_test.csv']\n",
    "test_bio_feature_filenames_class_1 = [f'{ds_dir}train_val_test__80_20/{classes[1]}_nosim.fa.matrix_test.csv']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312\n",
      "5462\n"
     ]
    }
   ],
   "source": [
    "# load positive and negative sequence data to construct ground label list\n",
    "\n",
    "with open(neg_filename,'r') as nf:\n",
    "    neg_examples = [seq.strip() for seq in nf.readlines()]\n",
    "    num_neg = len(neg_examples) # number of negative examples\n",
    "    print(num_neg)\n",
    "\n",
    "with open(pos_filename,'r') as pf:\n",
    "    pos_examples = [seq.strip() for seq in pf.readlines()]\n",
    "    num_pos = len(pos_examples) # number of positive examples\n",
    "    print(num_pos)    \n",
    "\n",
    "sequences_DS = neg_examples + pos_examples \n",
    "labels_DS = np.array([0]*num_neg + [1]*num_pos)   \n",
    "len(sequences_DS), len(labels_DS)\n",
    "\n",
    "scale_pos_weight = num_neg/num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2312, 292) (5462, 292) (7774, 292)\n"
     ]
    }
   ],
   "source": [
    "# load training + validation data\n",
    "\n",
    "bio_features_class0 = np.concatenate([pd.read_csv(bio_feature_filename, header=None, index_col=False).to_numpy() for bio_feature_filename in bio_feature_filenames_class_0], axis = 1)\n",
    "bio_features_class1 = np.concatenate([pd.read_csv(bio_feature_filename, header=None, index_col=False).to_numpy() for bio_feature_filename in bio_feature_filenames_class_1], axis = 1)\n",
    "\n",
    "neg_bio_features = bio_features_class0\n",
    "pos_bio_features = bio_features_class1\n",
    "\n",
    "bio_features_DS = np.concatenate([bio_features_class0, bio_features_class1], axis = 0)    \n",
    "print(neg_bio_features.shape, pos_bio_features.shape,bio_features_DS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 292) (1366, 292) (1945, 292) 1945\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "\n",
    "test_bio_features_class0 = np.concatenate([pd.read_csv(bio_feature_filename, header=None, index_col=False).to_numpy() for bio_feature_filename in test_bio_feature_filenames_class_0], axis = 1)\n",
    "test_bio_features_class1 = np.concatenate([pd.read_csv(bio_feature_filename, header=None, index_col=False).to_numpy() for bio_feature_filename in test_bio_feature_filenames_class_1], axis = 1)\n",
    "\n",
    "test_neg_bio_features = test_bio_features_class0\n",
    "test_pos_bio_features = test_bio_features_class1\n",
    "\n",
    "test_bio_features_DS = np.concatenate([test_bio_features_class0, test_bio_features_class1], axis = 0)    \n",
    "\n",
    "test_labels_DS = np.array([0]*test_bio_features_class0.shape[0] + [1]*test_bio_features_class1.shape[0])  \n",
    "print(test_neg_bio_features.shape, test_pos_bio_features.shape,test_bio_features_DS.shape, len(test_labels_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_mcc_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_pred = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'mcc', matthews_corrcoef(y_true, y_pred), True\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "\n",
    "def compute_sens_spec_mcc(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    #cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    specificity = tn/(fp+tn)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    \n",
    "    return {'specificity':specificity, 'sensitivity': sensitivity, 'mcc':matthews_corrcoef(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle the dataset (required as all negative class examples come first in the original)\n",
    "\n",
    "indx = list(range(len(labels_DS)))\n",
    "np.random.shuffle(indx)\n",
    "labels_DS_np = np.array(labels_DS)\n",
    "labels_shuf = labels_DS_np[indx]\n",
    "bio_features_shuf = bio_features_DS[indx,:]\n",
    "\n",
    "\n",
    "train_frac = 0.8\n",
    "val_frac = 1 - train_frac\n",
    "\n",
    "train_count = int(len(indx)*train_frac)\n",
    "val_count = len(indx) - train_count\n",
    "\n",
    "train_features = bio_features_shuf[:train_count,:]\n",
    "train_labels = labels_shuf[:train_count]\n",
    "\n",
    "val_features = bio_features_shuf[train_count:,:]\n",
    "val_labels = labels_shuf[train_count:]\n",
    "\n",
    "test_features = test_bio_features_DS\n",
    "test_labels = test_labels_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# skf = StratifiedKFold(n_splits=10)\n",
    "# kernel = 'poly'\n",
    "# C = 1\n",
    "# results_CV = []\n",
    "# for train_idx, val_idx in skf.split(bio_features_shuf, labels_shuf):\n",
    "#     k += 1\n",
    "#     train_features = bio_features_shuf[train_idx,:]\n",
    "#     train_labels = labels_shuf[train_idx]\n",
    "\n",
    "#     val_features = bio_features_shuf[val_idx,:]\n",
    "#     val_labels = labels_shuf[val_idx]\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     svm_clf = SVC(gamma='scale', kernel = kernel, C = C)\n",
    "#     svm_clf.fit(train_features, train_labels)\n",
    "#     end_time = time.time()\n",
    "#     print(end_time-start_time, 'seconds')\n",
    "    \n",
    "#     val_preds = svm_clf.predict(val_features)\n",
    "#     train_preds = svm_clf.predict(train_features)\n",
    "#     #np.sum(val_preds[val_labels==1] == val_labels[val_labels==1])/len(val_labels[val_labels==1])\n",
    "\n",
    "#     result = compute_sens_spec_mcc(val_labels, val_preds)\n",
    "#     results_CV.append(list(result.values()) )\n",
    "#     print(f'fold{k}:',result['mcc'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.values(), results_CV  \n",
    "# np.mean(results_CV, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    specificity sensitivity mcc\n",
      "kernel=poly, C=1: [0.00519294 0.99816883 0.02677993]\n",
      "kernel=poly, C=2: [0.00648977 0.9967038  0.02390304]\n",
      "kernel=poly, C=3: [0.0082195  0.99523893 0.02213555]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-92a2159c8389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msvm_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print(end_time-start_time, 'seconds')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "parameters = {'kernel':('rbf',), 'C':range(1, 10+1)}\n",
    "\n",
    "print('                    specificity', 'sensitivity', 'mcc')\n",
    "for kernel in parameters['kernel']:\n",
    "    for C in parameters['C']:\n",
    "        \n",
    "        results_CV = []\n",
    "        k = 0\n",
    "        for train_idx, val_idx in skf.split(bio_features_shuf, labels_shuf):\n",
    "            k += 1\n",
    "            train_features = bio_features_shuf[train_idx,:]\n",
    "            train_labels = labels_shuf[train_idx]\n",
    "\n",
    "            val_features = bio_features_shuf[val_idx,:]\n",
    "            val_labels = labels_shuf[val_idx]\n",
    "\n",
    "            start_time = time.time()\n",
    "            svm_clf = SVC(gamma='scale', kernel = kernel, C = C)\n",
    "            svm_clf.fit(train_features, train_labels)\n",
    "            end_time = time.time()\n",
    "            #print(end_time-start_time, 'seconds')\n",
    "\n",
    "            val_preds = svm_clf.predict(val_features)\n",
    "            train_preds = svm_clf.predict(train_features)\n",
    "            #np.sum(val_preds[val_labels==1] == val_labels[val_labels==1])/len(val_labels[val_labels==1])\n",
    "\n",
    "            result = compute_sens_spec_mcc(val_labels, val_preds)\n",
    "            results_CV.append(list(result.values()) )\n",
    "            #print(f'fold {02d:k}:', result)  \n",
    "            \n",
    "        results_CV = np.array(results_CV)\n",
    "        \n",
    "        print(f\"kernel={kernel}, C={C}:\", np.mean(results_CV, axis=0) )\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    specificity sensitivity mcc\n",
      "kernel=rbf, C=1: [0.82698849 0.84621601 0.64388982]\n",
      "kernel=rbf, C=2: [0.82829093 0.8539043  0.65456531]\n",
      "kernel=rbf, C=3: [0.82785897 0.85866386 0.66024144]\n",
      "kernel=rbf, C=4: [0.8226679  0.86232552 0.66067237]\n",
      "kernel=rbf, C=5: [0.82180397 0.86415602 0.66228625]\n",
      "kernel=rbf, C=6: [0.82007798 0.86635332 0.66372415]\n",
      "kernel=rbf, C=7: [0.81445495 0.86745105 0.66052932]\n",
      "kernel=rbf, C=8: [0.81142745 0.86873326 0.6597708 ]\n",
      "kernel=rbf, C=9: [0.81142932 0.86891625 0.6599914 ]\n",
      "kernel=rbf, C=10: [0.81099642 0.86928238 0.66013526]\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test spec., sens. mcc:\n",
      "0.8117443868739206 0.8638360175695461 0.6533761798120308\n"
     ]
    }
   ],
   "source": [
    "kernel_test = 'rbf'\n",
    "kernel_C = 5\n",
    "\n",
    "# SVM retrain\n",
    "svm_clf = SVC(gamma='scale', kernel = kernel_test, C = kernel_C)\n",
    "svm_clf.fit(bio_features_shuf, labels_shuf)\n",
    "\n",
    "test_preds = svm_clf.predict(test_features)\n",
    "\n",
    "\n",
    "test_result = compute_sens_spec_mcc(test_labels, test_preds)\n",
    "print(\"test spec., sens. mcc:\")\n",
    "print(test_result['specificity'], test_result['sensitivity'], test_result['mcc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reported results:\n",
    "###                      specificity        sensitivity        mcc\n",
    "### CV kernel=rbf, C=5: [0.82180397         0.86415602         0.66228625]\n",
    "### Testing:             0.8117443868739206 0.8638360175695461 0.6533761798120308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": [0.70545567 0.88594167 0.59602041]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_CV = []\n",
    "k = 0\n",
    "for train_idx, val_idx in skf.split(bio_features_shuf, labels_shuf):\n",
    "    k += 1\n",
    "    train_features = bio_features_shuf[train_idx,:]\n",
    "    train_labels = labels_shuf[train_idx]\n",
    "\n",
    "    val_features = bio_features_shuf[val_idx,:]\n",
    "    val_labels = labels_shuf[val_idx]\n",
    "\n",
    "    start_time = time.time()\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(train_features, train_labels)\n",
    "\n",
    "    end_time = time.time()\n",
    "    #print(end_time-start_time, 'seconds')\n",
    "\n",
    "    val_preds = clf.predict(val_features)\n",
    "\n",
    "    result = compute_sens_spec_mcc(val_labels, val_preds)\n",
    "    results_CV.append(list(result.values()) )\n",
    "    #print(f'fold {02d:k}:', result)  \n",
    "\n",
    "results_CV = np.array(results_CV)\n",
    "\n",
    "print(f\":\", np.mean(results_CV, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation spec., sens. mcc:\n",
      "0.7150259067357513 0.8879941434846267 0.6067087324217663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarik/anaconda3/envs/project_selfie/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(bio_features_shuf, labels_shuf)\n",
    "\n",
    "test_preds = clf.predict(test_features)\n",
    "#np.sum(val_preds[val_labels==1] == val_labels[val_labels==1])/len(val_labels[val_labels==1])\n",
    "\n",
    "\n",
    "test_result = compute_sens_spec_mcc(test_labels, test_preds)\n",
    "print(\"validation spec., sens. mcc:\")\n",
    "print(test_result['specificity'], test_result['sensitivity'], test_result['mcc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
